{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId  Transported\n",
       "0     0013_01        False\n",
       "1     0018_01        False\n",
       "2     0019_01        False\n",
       "3     0021_01        False\n",
       "4     0023_01        False"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the sample submission file\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "sample_submission.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId       0\n",
       "HomePlanet       87\n",
       "CryoSleep        93\n",
       "Cabin           100\n",
       "Destination      92\n",
       "Age              91\n",
       "VIP              93\n",
       "RoomService      82\n",
       "FoodCourt       106\n",
       "ShoppingMall     98\n",
       "Spa             101\n",
       "VRDeck           80\n",
       "Name             94\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the training data\n",
    "train_data = pd.read_csv('train.csv')\n",
    "train_data.head()\n",
    "\n",
    "# Load the testing data\n",
    "test_data = pd.read_csv('test.csv')\n",
    "test_data.head()\n",
    "\n",
    "# Checking for missing values in the training data\n",
    "train_data.isnull().sum()\n",
    "# Checking for missing values in the test data\n",
    "test_data.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId       0\n",
       "HomePlanet      201\n",
       "CryoSleep       217\n",
       "Cabin           199\n",
       "Destination     182\n",
       "Age             179\n",
       "VIP             203\n",
       "RoomService     181\n",
       "FoodCourt       183\n",
       "ShoppingMall    208\n",
       "Spa             183\n",
       "VRDeck          188\n",
       "Name            200\n",
       "Transported       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values in the training data\n",
    "train_data.isnull().sum()\n",
    "\n",
    "# Reload the training and testing datasets\n",
    "\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Check for missing values in the training data\n",
    "train_data.isnull().sum()\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Reload the training and testing datasets\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Check for missing values in the training data\n",
    "train_data.isnull().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8693 entries, 0 to 8692\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   PassengerId   8693 non-null   object \n",
      " 1   HomePlanet    8492 non-null   object \n",
      " 2   CryoSleep     8476 non-null   object \n",
      " 3   Cabin         8494 non-null   object \n",
      " 4   Destination   8511 non-null   object \n",
      " 5   Age           8514 non-null   float64\n",
      " 6   VIP           8490 non-null   object \n",
      " 7   RoomService   8512 non-null   float64\n",
      " 8   FoodCourt     8510 non-null   float64\n",
      " 9   ShoppingMall  8485 non-null   float64\n",
      " 10  Spa           8510 non-null   float64\n",
      " 11  VRDeck        8505 non-null   float64\n",
      " 12  Name          8493 non-null   object \n",
      " 13  Transported   8693 non-null   bool   \n",
      "dtypes: bool(1), float64(6), object(7)\n",
      "memory usage: 891.5+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4277 entries, 0 to 4276\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   PassengerId   4277 non-null   object \n",
      " 1   HomePlanet    4190 non-null   object \n",
      " 2   CryoSleep     4184 non-null   object \n",
      " 3   Cabin         4177 non-null   object \n",
      " 4   Destination   4185 non-null   object \n",
      " 5   Age           4186 non-null   float64\n",
      " 6   VIP           4184 non-null   object \n",
      " 7   RoomService   4195 non-null   float64\n",
      " 8   FoodCourt     4171 non-null   float64\n",
      " 9   ShoppingMall  4179 non-null   float64\n",
      " 10  Spa           4176 non-null   float64\n",
      " 11  VRDeck        4197 non-null   float64\n",
      " 12  Name          4183 non-null   object \n",
      "dtypes: float64(6), object(7)\n",
      "memory usage: 434.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Display the data types and any missing values in the training dataset\n",
    "train_data.info()\n",
    "\n",
    "# Display the data types and any missing values in the testing dataset\n",
    "test_data.info()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8693, 15268), (4277, 15268))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Drop the 'Name' column\n",
    "train_data = train_data.drop('Name', axis=1)\n",
    "test_data = test_data.drop('Name', axis=1)\n",
    "\n",
    "# Convert boolean columns to int\n",
    "for col in ['CryoSleep', 'VIP', 'Transported']:\n",
    "    if col in train_data.columns:\n",
    "        train_data[col] = train_data[col].astype(int)\n",
    "    if col in test_data.columns:\n",
    "        test_data[col] = test_data[col].astype(int)\n",
    "\n",
    "# Separate features and target variable in the training dataset\n",
    "X_train = train_data.drop('Transported', axis=1)\n",
    "y_train = train_data['Transported']\n",
    "\n",
    "# Define the columns for the different preprocessing steps\n",
    "num_cols = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
    "cat_cols = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Define the preprocessing steps\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine the preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_cols),\n",
    "        ('cat', cat_transformer, cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Apply the preprocessing steps to the training data\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Apply the preprocessing steps to the testing data\n",
    "X_test_preprocessed = preprocessor.transform(test_data)\n",
    "\n",
    "# Display the shape of the preprocessed data\n",
    "X_train_preprocessed.shape, X_test_preprocessed.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8693, 15268), (4277, 15268))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impute missing values in boolean columns with the mode\n",
    "for col in ['CryoSleep', 'VIP']:\n",
    "    train_data[col].fillna(train_data[col].mode()[0], inplace=True)\n",
    "    test_data[col].fillna(test_data[col].mode()[0], inplace=True)\n",
    "\n",
    "# Convert boolean columns to int\n",
    "for col in ['CryoSleep', 'VIP']:\n",
    "    train_data[col] = train_data[col].astype(int)\n",
    "    test_data[col] = test_data[col].astype(int)\n",
    "\n",
    "# Separate features and target variable in the training dataset\n",
    "X_train = train_data.drop('Transported', axis=1)\n",
    "y_train = train_data['Transported']\n",
    "\n",
    "# Apply the preprocessing steps to the training data\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Apply the preprocessing steps to the testing data\n",
    "X_test_preprocessed = preprocessor.transform(test_data)\n",
    "\n",
    "# Display the shape of the preprocessed data\n",
    "X_train_preprocessed.shape, X_test_preprocessed.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8693, 15268), (4277, 15268))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the preprocessing steps\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine the preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_cols),\n",
    "        ('cat', cat_transformer, cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Apply the preprocessing steps to the training data\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Apply the preprocessing steps to the testing data\n",
    "X_test_preprocessed = preprocessor.transform(test_data)\n",
    "\n",
    "# Display the shape of the preprocessed data\n",
    "X_train_preprocessed.shape, X_test_preprocessed.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8693, 23742), (4277, 23742))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the columns for the different preprocessing steps\n",
    "num_cols = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
    "cat_cols = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Define the preprocessing steps\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine the preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_cols),\n",
    "        ('cat', cat_transformer, cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Apply the preprocessing steps to the training data\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Apply the preprocessing steps to the testing data\n",
    "X_test_preprocessed = preprocessor.transform(test_data)\n",
    "\n",
    "# Display the shape of the preprocessed data\n",
    "X_train_preprocessed.shape, X_test_preprocessed.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8693, 50), (4277, 50))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Define the TruncatedSVD transformer\n",
    "svd = TruncatedSVD(n_components=50, random_state=42)\n",
    "\n",
    "# Apply TruncatedSVD to the training data\n",
    "X_train_svd = svd.fit_transform(X_train_preprocessed)\n",
    "\n",
    "# Apply TruncatedSVD to the testing data\n",
    "X_test_svd = svd.transform(X_test_preprocessed)\n",
    "\n",
    "# Display the shape of the transformed data\n",
    "X_train_svd.shape, X_test_svd.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": [
       "({'min_samples_split': 2, 'max_depth': 10}, 0.7381803491418358)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define the model\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Define the grid of hyperparameters\n",
    "param_dist_dt = {\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "# Set up the randomized search\n",
    "random_search_dt = RandomizedSearchCV(dt, param_dist_dt, cv=5, scoring='accuracy', n_iter=10, random_state=42)\n",
    "\n",
    "# Fit the model and tune the hyperparameters\n",
    "random_search_dt.fit(X_train_svd, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_dt = random_search_dt.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters and the accuracy of the best model\n",
    "random_search_dt.best_params_, random_search_dt.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5382511542220673"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Define the model\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Fit the model to the data\n",
    "gnb.fit(X_train_svd, y_train)\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "scores_gnb = cross_val_score(gnb, X_train_svd, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Print the accuracy of the model\n",
    "scores_gnb.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.777524879383215"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# Define the model\n",
    "svc = svm.SVC(kernel='linear', C=1.0, random_state=42)\n",
    "\n",
    "# Fit the model to the data\n",
    "svc.fit(X_train_svd, y_train)\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "scores_svc = cross_val_score(svc, X_train_svd, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Print the accuracy of the model\n",
    "scores_svc.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId  Transported\n",
       "0     0013_01         True\n",
       "1     0018_01        False\n",
       "2     0019_01         True\n",
       "3     0021_01         True\n",
       "4     0023_01         True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on the testing data\n",
    "y_test_pred = svc.predict(X_test_svd)\n",
    "\n",
    "# Create a DataFrame for the submission file\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_data['PassengerId'],\n",
    "    'Transported': y_test_pred\n",
    "})\n",
    "\n",
    "# Save the submission file\n",
    "submission.to_csv('submission_optimized.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the submission file\n",
    "submission.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7646390165108183"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model to the data\n",
    "rf.fit(X_train_svd, y_train)\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "scores_rf = cross_val_score(rf, X_train_svd, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Print the accuracy of the model\n",
    "scores_rf.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId  Transported\n",
       "0     0013_01         True\n",
       "1     0018_01        False\n",
       "2     0019_01         True\n",
       "3     0021_01         True\n",
       "4     0023_01         True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the 'Transported' column back to boolean format\n",
    "submission['Transported'] = submission['Transported'].astype(bool)\n",
    "\n",
    "# Save the submission file\n",
    "submission.to_csv('submission_rf.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the submission file\n",
    "submission.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": [
       "0.7833901869452637"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Define the preprocessing steps\n",
    "num_transformer_complex = Pipeline(steps=[\n",
    "    ('imputer', IterativeImputer(random_state=42)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Combine the preprocessing steps\n",
    "preprocessor_complex = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer_complex, num_cols),\n",
    "        ('cat', cat_transformer, cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Apply the preprocessing steps to the training data\n",
    "X_train_preprocessed_complex = preprocessor_complex.fit_transform(X_train)\n",
    "\n",
    "# Apply the preprocessing steps to the testing data\n",
    "X_test_preprocessed_complex = preprocessor_complex.transform(test_data)\n",
    "\n",
    "# Apply TruncatedSVD to the training data\n",
    "X_train_svd_complex = svd.fit_transform(X_train_preprocessed_complex)\n",
    "\n",
    "# Apply TruncatedSVD to the testing data\n",
    "X_test_svd_complex = svd.transform(X_test_preprocessed_complex)\n",
    "\n",
    "# Define the model\n",
    "mlp = MLPClassifier(random_state=42)\n",
    "\n",
    "# Fit the model to the data\n",
    "mlp.fit(X_train_svd_complex, y_train)\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "scores_mlp = cross_val_score(mlp, X_train_svd_complex, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Print the accuracy of the model\n",
    "scores_mlp.mean()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "not better than normal forest.\n",
    "how about we try an ensemble method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "# Define the base models\n",
    "dt = DecisionTreeClassifier(max_depth=5, min_samples_split=2, random_state=42)\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "svc = svm.SVC(kernel='linear', C=1.0, probability=True, random_state=42)\n",
    "\n",
    "# Define the ensemble model\n",
    "ensemble_model = VotingClassifier(estimators=[('dt', dt), ('rf', rf), ('svc', svc)], voting='soft')\n",
    "\n",
    "# Fit the model to the data\n",
    "ensemble_model.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_test_pred_ensemble = ensemble_model.predict(X_test_preprocessed)\n",
    "\n",
    "# Create a DataFrame for the submission file\n",
    "submission_ensemble = pd.DataFrame({\n",
    "    'PassengerId': test_data['PassengerId'],\n",
    "    'Transported': y_test_pred_ensemble\n",
    "})\n",
    "\n",
    "# Save the submission file\n",
    "submission_ensemble.to_csv('submission_ensemble.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
